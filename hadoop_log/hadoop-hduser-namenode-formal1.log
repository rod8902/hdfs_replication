2015-12-15 13:32:16,107 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = formal1/10.0.1.71
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.4.1
STARTUP_MSG:   classpath = /usr/local/hadoop/etc/hadoop:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-auth-2.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/common/lib/zookeeper-3.4.5.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/local/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/local/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-el-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-annotations-2.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-xc-1.8.8.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/junit-4.8.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.8.8.jar:/usr/local/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-core-asl-1.8.8.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.8.8.jar:/usr/local/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/local/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.4.1-tests.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.4.1.jar:/usr/local/hadoop/share/hadoop/common/hadoop-nfs-2.4.1.jar:/usr/local/hadoop/share/hadoop/hdfs:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.8.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.8.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.4.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.4.1-tests.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.5.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-xc-1.8.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.8.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.8.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.8.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/junit-4.10.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.8.8.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.8.8.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.4.1-tests.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.4.1.jar:/usr/local/hadoop/contrib/capacity-scheduler/*.jar:/usr/local/hadoop/contrib/capacity-scheduler/*.jar:/usr/local/hadoop/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'hduser' on 2015-12-03T16:37Z
STARTUP_MSG:   java = 1.7.0_79
************************************************************/
2015-12-15 13:32:16,121 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2015-12-15 13:32:16,123 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2015-12-15 13:32:16,391 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-12-15 13:32:16,579 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-12-15 13:32:16,579 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2015-12-15 13:32:16,581 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://master:54310
2015-12-15 13:32:16,581 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use master:54310 to access this namenode/service.
2015-12-15 13:32:16,909 INFO org.apache.hadoop.hdfs.DFSUtil: Starting web server as: ${dfs.web.authentication.kerberos.principal}
2015-12-15 13:32:16,909 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2015-12-15 13:32:16,976 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-12-15 13:32:16,980 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2015-12-15 13:32:16,992 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2015-12-15 13:32:16,994 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2015-12-15 13:32:16,994 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-12-15 13:32:16,994 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-12-15 13:32:17,024 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2015-12-15 13:32:17,025 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2015-12-15 13:32:17,063 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2015-12-15 13:32:17,063 INFO org.mortbay.log: jetty-6.1.26
2015-12-15 13:32:17,307 WARN org.apache.hadoop.security.authentication.server.AuthenticationFilter: 'signature.secret' configuration not set, using a random value as secret
2015-12-15 13:32:17,354 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50070
2015-12-15 13:32:17,381 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of dataloss due to lack of redundant storage directories!
2015-12-15 13:32:17,381 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of dataloss due to lack of redundant storage directories!
2015-12-15 13:32:17,416 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2015-12-15 13:32:17,445 INFO org.apache.hadoop.hdfs.server.namenode.HostFileManager: read includes:
HostSet(
)
2015-12-15 13:32:17,446 INFO org.apache.hadoop.hdfs.server.namenode.HostFileManager: read excludes:
HostSet(
)
2015-12-15 13:32:17,448 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2015-12-15 13:32:17,448 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2015-12-15 13:32:17,451 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2015-12-15 13:32:17,451 INFO org.apache.hadoop.util.GSet: VM type       = 32-bit
2015-12-15 13:32:17,454 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2015-12-15 13:32:17,454 INFO org.apache.hadoop.util.GSet: capacity      = 2^22 = 4194304 entries
2015-12-15 13:32:17,465 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2015-12-15 13:32:17,465 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 3
2015-12-15 13:32:17,465 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2015-12-15 13:32:17,465 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2015-12-15 13:32:17,465 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2015-12-15 13:32:17,465 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2015-12-15 13:32:17,465 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2015-12-15 13:32:17,465 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2015-12-15 13:32:17,465 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2015-12-15 13:32:17,471 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hduser (auth:SIMPLE)
2015-12-15 13:32:17,471 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2015-12-15 13:32:17,471 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = false
2015-12-15 13:32:17,472 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2015-12-15 13:32:17,473 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2015-12-15 13:32:17,515 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2015-12-15 13:32:17,515 INFO org.apache.hadoop.util.GSet: VM type       = 32-bit
2015-12-15 13:32:17,515 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2015-12-15 13:32:17,515 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2015-12-15 13:32:17,519 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2015-12-15 13:32:17,525 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2015-12-15 13:32:17,525 INFO org.apache.hadoop.util.GSet: VM type       = 32-bit
2015-12-15 13:32:17,525 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2015-12-15 13:32:17,525 INFO org.apache.hadoop.util.GSet: capacity      = 2^19 = 524288 entries
2015-12-15 13:32:17,626 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2015-12-15 13:32:17,626 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2015-12-15 13:32:17,626 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2015-12-15 13:32:17,627 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2015-12-15 13:32:17,628 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2015-12-15 13:32:17,630 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2015-12-15 13:32:17,630 INFO org.apache.hadoop.util.GSet: VM type       = 32-bit
2015-12-15 13:32:17,630 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
2015-12-15 13:32:17,630 INFO org.apache.hadoop.util.GSet: capacity      = 2^16 = 65536 entries
2015-12-15 13:32:17,634 INFO org.apache.hadoop.hdfs.server.namenode.AclConfigFlag: ACLs enabled? false
2015-12-15 13:32:17,699 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/hduser/tmp/hadoop/dfs/name/in_use.lock acquired by nodename 20947@formal1
2015-12-15 13:32:17,797 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /home/hduser/tmp/hadoop/dfs/name/current
2015-12-15 13:32:17,798 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: No edit log streams selected.
2015-12-15 13:32:17,862 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2015-12-15 13:32:17,966 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2015-12-15 13:32:17,966 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /home/hduser/tmp/hadoop/dfs/name/current/fsimage_0000000000000000000
2015-12-15 13:32:17,972 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2015-12-15 13:32:17,972 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1
2015-12-15 13:32:18,133 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2015-12-15 13:32:18,134 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 500 msecs
2015-12-15 13:32:18,305 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to master:54310
2015-12-15 13:32:18,329 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2015-12-15 13:32:18,345 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 54310
2015-12-15 13:32:18,655 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2015-12-15 13:32:18,706 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of blocks under construction: 0
2015-12-15 13:32:18,707 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of blocks under construction: 0
2015-12-15 13:32:18,707 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2015-12-15 13:32:18,708 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 1 secs
2015-12-15 13:32:18,708 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2015-12-15 13:32:18,708 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2015-12-15 13:32:18,726 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 0
2015-12-15 13:32:18,726 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2015-12-15 13:32:18,726 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2015-12-15 13:32:18,726 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2015-12-15 13:32:18,726 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2015-12-15 13:32:18,726 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 18 msec
2015-12-15 13:32:18,748 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2015-12-15 13:32:18,748 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 54310: starting
2015-12-15 13:32:18,750 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: master/10.0.1.71:54310
2015-12-15 13:32:18,750 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2015-12-15 13:32:18,754 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2015-12-15 13:32:18,754 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning because of pending operations
2015-12-15 13:32:18,755 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2015-12-15 13:32:22,954 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.1.74, datanodeUuid=4806a124-9a2d-4991-a357-68d369de7e57, infoPort=50075, ipcPort=50020, storageInfo=lv=-55;cid=CID-13130253-4de0-4c2b-8349-2237a837313e;nsid=748937504;c=0) storage 4806a124-9a2d-4991-a357-68d369de7e57
2015-12-15 13:32:22,959 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.1.74:50010
2015-12-15 13:32:22,989 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.1.71, datanodeUuid=22a11d2d-2c2a-4d8a-921c-620e8c247a51, infoPort=50075, ipcPort=50020, storageInfo=lv=-55;cid=CID-13130253-4de0-4c2b-8349-2237a837313e;nsid=748937504;c=0) storage 22a11d2d-2c2a-4d8a-921c-620e8c247a51
2015-12-15 13:32:22,990 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.1.71:50010
2015-12-15 13:32:23,073 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-485dd6d9-1d17-4b52-89ea-7dbdfedd43f6 for DN 10.0.1.74:50010
2015-12-15 13:32:23,074 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-01d6a639-f497-4e82-9260-5a273f48eddc for DN 10.0.1.71:50010
2015-12-15 13:32:23,122 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from org.apache.hadoop.hdfs.server.protocol.DatanodeStorage@737bf8fe after starting up or becoming active. Its block contents are no longer considered stale
2015-12-15 13:32:23,122 INFO BlockStateChange: BLOCK* processReport: from storage DS-01d6a639-f497-4e82-9260-5a273f48eddc node DatanodeRegistration(10.0.1.71, datanodeUuid=22a11d2d-2c2a-4d8a-921c-620e8c247a51, infoPort=50075, ipcPort=50020, storageInfo=lv=-55;cid=CID-13130253-4de0-4c2b-8349-2237a837313e;nsid=748937504;c=0), blocks: 0, processing time: 2 msecs
2015-12-15 13:32:23,122 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from org.apache.hadoop.hdfs.server.protocol.DatanodeStorage@c0d7920a after starting up or becoming active. Its block contents are no longer considered stale
2015-12-15 13:32:23,122 INFO BlockStateChange: BLOCK* processReport: from storage DS-485dd6d9-1d17-4b52-89ea-7dbdfedd43f6 node DatanodeRegistration(10.0.1.74, datanodeUuid=4806a124-9a2d-4991-a357-68d369de7e57, infoPort=50075, ipcPort=50020, storageInfo=lv=-55;cid=CID-13130253-4de0-4c2b-8349-2237a837313e;nsid=748937504;c=0), blocks: 0, processing time: 0 msecs
2015-12-15 13:32:32,277 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.1.77, datanodeUuid=dae6a797-6b1c-44dd-a727-8fc62da6ee58, infoPort=50075, ipcPort=50020, storageInfo=lv=-55;cid=CID-13130253-4de0-4c2b-8349-2237a837313e;nsid=748937504;c=0) storage dae6a797-6b1c-44dd-a727-8fc62da6ee58
2015-12-15 13:32:32,278 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.1.77:50010
2015-12-15 13:32:32,311 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-7e1eec55-3690-41ef-a096-0965f3bfd294 for DN 10.0.1.77:50010
2015-12-15 13:32:32,328 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from org.apache.hadoop.hdfs.server.protocol.DatanodeStorage@2761b178 after starting up or becoming active. Its block contents are no longer considered stale
2015-12-15 13:32:32,329 INFO BlockStateChange: BLOCK* processReport: from storage DS-7e1eec55-3690-41ef-a096-0965f3bfd294 node DatanodeRegistration(10.0.1.77, datanodeUuid=dae6a797-6b1c-44dd-a727-8fc62da6ee58, infoPort=50075, ipcPort=50020, storageInfo=lv=-55;cid=CID-13130253-4de0-4c2b-8349-2237a837313e;nsid=748937504;c=0), blocks: 0, processing time: 1 msecs
2015-12-15 13:32:32,913 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.1.72, datanodeUuid=c788a1bc-2dc8-486e-93f7-0bbfc46ff670, infoPort=50075, ipcPort=50020, storageInfo=lv=-55;cid=CID-13130253-4de0-4c2b-8349-2237a837313e;nsid=748937504;c=0) storage c788a1bc-2dc8-486e-93f7-0bbfc46ff670
2015-12-15 13:32:32,914 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.1.72:50010
2015-12-15 13:32:32,916 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.1.76, datanodeUuid=0e673a5a-4791-4509-9820-288c357432e6, infoPort=50075, ipcPort=50020, storageInfo=lv=-55;cid=CID-13130253-4de0-4c2b-8349-2237a837313e;nsid=748937504;c=0) storage 0e673a5a-4791-4509-9820-288c357432e6
2015-12-15 13:32:32,917 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.1.76:50010
2015-12-15 13:32:32,946 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-523ac735-f848-47ac-bb54-5a6837e86db3 for DN 10.0.1.72:50010
2015-12-15 13:32:32,948 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-3d94ed3c-5f4b-43ca-bd30-94e88944fa04 for DN 10.0.1.76:50010
2015-12-15 13:32:32,966 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from org.apache.hadoop.hdfs.server.protocol.DatanodeStorage@e737aca6 after starting up or becoming active. Its block contents are no longer considered stale
2015-12-15 13:32:32,966 INFO BlockStateChange: BLOCK* processReport: from storage DS-3d94ed3c-5f4b-43ca-bd30-94e88944fa04 node DatanodeRegistration(10.0.1.76, datanodeUuid=0e673a5a-4791-4509-9820-288c357432e6, infoPort=50075, ipcPort=50020, storageInfo=lv=-55;cid=CID-13130253-4de0-4c2b-8349-2237a837313e;nsid=748937504;c=0), blocks: 0, processing time: 0 msecs
2015-12-15 13:32:32,978 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from org.apache.hadoop.hdfs.server.protocol.DatanodeStorage@181b2a73 after starting up or becoming active. Its block contents are no longer considered stale
2015-12-15 13:32:32,978 INFO BlockStateChange: BLOCK* processReport: from storage DS-523ac735-f848-47ac-bb54-5a6837e86db3 node DatanodeRegistration(10.0.1.72, datanodeUuid=c788a1bc-2dc8-486e-93f7-0bbfc46ff670, infoPort=50075, ipcPort=50020, storageInfo=lv=-55;cid=CID-13130253-4de0-4c2b-8349-2237a837313e;nsid=748937504;c=0), blocks: 0, processing time: 0 msecs
2015-12-15 13:32:33,057 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(10.0.1.73, datanodeUuid=d82b69d0-2e60-4c14-8db8-068956b6e9e0, infoPort=50075, ipcPort=50020, storageInfo=lv=-55;cid=CID-13130253-4de0-4c2b-8349-2237a837313e;nsid=748937504;c=0) storage d82b69d0-2e60-4c14-8db8-068956b6e9e0
2015-12-15 13:32:33,057 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/10.0.1.73:50010
2015-12-15 13:32:33,093 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-bc2037c4-a713-429d-aac2-0ce6ad2e2605 for DN 10.0.1.73:50010
2015-12-15 13:32:33,110 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from org.apache.hadoop.hdfs.server.protocol.DatanodeStorage@9bc3df97 after starting up or becoming active. Its block contents are no longer considered stale
2015-12-15 13:32:33,110 INFO BlockStateChange: BLOCK* processReport: from storage DS-bc2037c4-a713-429d-aac2-0ce6ad2e2605 node DatanodeRegistration(10.0.1.73, datanodeUuid=d82b69d0-2e60-4c14-8db8-068956b6e9e0, infoPort=50075, ipcPort=50020, storageInfo=lv=-55;cid=CID-13130253-4de0-4c2b-8349-2237a837313e;nsid=748937504;c=0), blocks: 0, processing time: 0 msecs
2015-12-15 13:32:48,755 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2015-12-15 13:32:48,756 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2015-12-15 13:33:11,307 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /test3.mp4._COPYING_. BP-533550338-10.0.1.71-1450153894482 blk_1073741825_1001{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-01d6a639-f497-4e82-9260-5a273f48eddc:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-3d94ed3c-5f4b-43ca-bd30-94e88944fa04:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-bc2037c4-a713-429d-aac2-0ce6ad2e2605:NORMAL|RBW]]}
2015-12-15 13:33:18,755 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2015-12-15 13:33:18,757 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2015-12-15 13:33:28,512 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 10.0.1.71
2015-12-15 13:33:28,512 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2015-12-15 13:33:28,512 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 1
2015-12-15 13:33:28,512 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 6 Total time for transactions(ms): 33 Number of transactions batched in Syncs: 0 Number of syncs: 4 SyncTimes(ms): 94 
2015-12-15 13:33:28,539 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 6 Total time for transactions(ms): 33 Number of transactions batched in Syncs: 0 Number of syncs: 5 SyncTimes(ms): 119 
2015-12-15 13:33:28,540 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/hduser/tmp/hadoop/dfs/name/current/edits_inprogress_0000000000000000001 -> /home/hduser/tmp/hadoop/dfs/name/current/edits_0000000000000000001-0000000000000000006
2015-12-15 13:33:28,540 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 7
2015-12-15 13:33:35,550 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.14s at 0.00 KB/s
2015-12-15 13:33:35,550 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000006 size 528 bytes.
2015-12-15 13:33:35,719 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 0
2015-12-15 13:33:40,851 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.1.73:50010 is added to blk_1073741825_1001{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-01d6a639-f497-4e82-9260-5a273f48eddc:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-3d94ed3c-5f4b-43ca-bd30-94e88944fa04:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-bc2037c4-a713-429d-aac2-0ce6ad2e2605:NORMAL|RBW]]} size 0
2015-12-15 13:33:40,908 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: rod_test! blockNum = 2
2015-12-15 13:33:40,908 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.1.76:50010 is added to blk_1073741825_1001{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-01d6a639-f497-4e82-9260-5a273f48eddc:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-3d94ed3c-5f4b-43ca-bd30-94e88944fa04:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-bc2037c4-a713-429d-aac2-0ce6ad2e2605:NORMAL|RBW]]} size 0
2015-12-15 13:33:40,908 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: rod_test! t_DD != null
2015-12-15 13:33:40,908 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: rod_test! favoredDatanodeDescriptors != null
2015-12-15 13:33:40,908 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.1.71:50010 is added to blk_1073741825_1001{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-01d6a639-f497-4e82-9260-5a273f48eddc:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-3d94ed3c-5f4b-43ca-bd30-94e88944fa04:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-bc2037c4-a713-429d-aac2-0ce6ad2e2605:NORMAL|RBW]]} size 0
2015-12-15 13:33:40,909 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /test3.mp4._COPYING_. BP-533550338-10.0.1.71-1450153894482 blk_1073741826_1002{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-bc2037c4-a713-429d-aac2-0ce6ad2e2605:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-523ac735-f848-47ac-bb54-5a6837e86db3:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-3d94ed3c-5f4b-43ca-bd30-94e88944fa04:NORMAL|RBW]]}
2015-12-15 13:33:48,756 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2015-12-15 13:33:48,757 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2015-12-15 13:33:55,019 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: list corrupt file blocks returned: 0
2015-12-15 13:33:57,998 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.1.76:50010 is added to blk_1073741826_1002{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-bc2037c4-a713-429d-aac2-0ce6ad2e2605:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-523ac735-f848-47ac-bb54-5a6837e86db3:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-3d94ed3c-5f4b-43ca-bd30-94e88944fa04:NORMAL|RBW]]} size 0
2015-12-15 13:33:58,004 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.1.72:50010 is added to blk_1073741826_1002{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-bc2037c4-a713-429d-aac2-0ce6ad2e2605:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-523ac735-f848-47ac-bb54-5a6837e86db3:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-3d94ed3c-5f4b-43ca-bd30-94e88944fa04:NORMAL|RBW]]} size 0
2015-12-15 13:33:58,007 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.1.73:50010 is added to blk_1073741826_1002{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-bc2037c4-a713-429d-aac2-0ce6ad2e2605:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-523ac735-f848-47ac-bb54-5a6837e86db3:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-3d94ed3c-5f4b-43ca-bd30-94e88944fa04:NORMAL|RBW]]} size 0
2015-12-15 13:33:58,010 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: rod_test! blockNum = 3
2015-12-15 13:33:58,010 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: rod_test! t_DD != null
2015-12-15 13:33:58,010 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: rod_test! favoredDatanodeDescriptors != null
2015-12-15 13:33:58,010 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: rod_test! blockNum > 2
2015-12-15 13:33:58,010 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: rod_test! t_blocks.length = 2
2015-12-15 13:33:58,011 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /test3.mp4._COPYING_. BP-533550338-10.0.1.71-1450153894482 blk_1073741827_1003{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-01d6a639-f497-4e82-9260-5a273f48eddc:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-3d94ed3c-5f4b-43ca-bd30-94e88944fa04:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-bc2037c4-a713-429d-aac2-0ce6ad2e2605:NORMAL|RBW]]}
2015-12-15 13:34:15,938 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.1.73:50010 is added to blk_1073741827_1003{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-01d6a639-f497-4e82-9260-5a273f48eddc:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-3d94ed3c-5f4b-43ca-bd30-94e88944fa04:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-bc2037c4-a713-429d-aac2-0ce6ad2e2605:NORMAL|RBW]]} size 0
2015-12-15 13:34:15,940 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.1.76:50010 is added to blk_1073741827_1003{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-01d6a639-f497-4e82-9260-5a273f48eddc:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-3d94ed3c-5f4b-43ca-bd30-94e88944fa04:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-bc2037c4-a713-429d-aac2-0ce6ad2e2605:NORMAL|RBW]]} size 0
2015-12-15 13:34:15,941 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.1.71:50010 is added to blk_1073741827_1003{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-01d6a639-f497-4e82-9260-5a273f48eddc:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-3d94ed3c-5f4b-43ca-bd30-94e88944fa04:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-bc2037c4-a713-429d-aac2-0ce6ad2e2605:NORMAL|RBW]]} size 0
2015-12-15 13:34:15,944 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: rod_test! blockNum = 4
2015-12-15 13:34:15,944 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: rod_test! t_DD != null
2015-12-15 13:34:15,944 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: rod_test! favoredDatanodeDescriptors != null
2015-12-15 13:34:15,944 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: rod_test! blockNum > 2
2015-12-15 13:34:15,944 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: rod_test! t_blocks.length = 3
2015-12-15 13:34:15,946 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /test3.mp4._COPYING_. BP-533550338-10.0.1.71-1450153894482 blk_1073741828_1004{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-bc2037c4-a713-429d-aac2-0ce6ad2e2605:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-7e1eec55-3690-41ef-a096-0965f3bfd294:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-3d94ed3c-5f4b-43ca-bd30-94e88944fa04:NORMAL|RBW]]}
2015-12-15 13:34:18,756 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2015-12-15 13:34:18,757 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2015-12-15 13:34:21,015 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.1.76:50010 is added to blk_1073741828_1004{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-bc2037c4-a713-429d-aac2-0ce6ad2e2605:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-7e1eec55-3690-41ef-a096-0965f3bfd294:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-3d94ed3c-5f4b-43ca-bd30-94e88944fa04:NORMAL|RBW]]} size 0
2015-12-15 13:34:21,019 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.1.77:50010 is added to blk_1073741828_1004{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-bc2037c4-a713-429d-aac2-0ce6ad2e2605:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-7e1eec55-3690-41ef-a096-0965f3bfd294:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-3d94ed3c-5f4b-43ca-bd30-94e88944fa04:NORMAL|RBW]]} size 0
2015-12-15 13:34:21,023 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.1.73:50010 is added to blk_1073741828_1004{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-bc2037c4-a713-429d-aac2-0ce6ad2e2605:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-7e1eec55-3690-41ef-a096-0965f3bfd294:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-3d94ed3c-5f4b-43ca-bd30-94e88944fa04:NORMAL|RBW]]} size 0
2015-12-15 13:34:21,024 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: rod_test! blockNum = 5
2015-12-15 13:34:21,024 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: rod_test! t_DD != null
2015-12-15 13:34:21,024 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: rod_test! favoredDatanodeDescriptors != null
2015-12-15 13:34:21,024 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: rod_test! blockNum > 2
2015-12-15 13:34:21,024 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: rod_test! t_blocks.length = 4
2015-12-15 13:34:21,025 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /test3.mp4._COPYING_. BP-533550338-10.0.1.71-1450153894482 blk_1073741829_1005{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-01d6a639-f497-4e82-9260-5a273f48eddc:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-3d94ed3c-5f4b-43ca-bd30-94e88944fa04:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-7e1eec55-3690-41ef-a096-0965f3bfd294:NORMAL|RBW]]}
2015-12-15 13:34:35,263 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.1.77:50010 is added to blk_1073741829_1005{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-01d6a639-f497-4e82-9260-5a273f48eddc:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-3d94ed3c-5f4b-43ca-bd30-94e88944fa04:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-7e1eec55-3690-41ef-a096-0965f3bfd294:NORMAL|RBW]]} size 0
2015-12-15 13:34:35,266 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.1.76:50010 is added to blk_1073741829_1005{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-01d6a639-f497-4e82-9260-5a273f48eddc:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-3d94ed3c-5f4b-43ca-bd30-94e88944fa04:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-7e1eec55-3690-41ef-a096-0965f3bfd294:NORMAL|RBW]]} size 0
2015-12-15 13:34:35,267 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.1.71:50010 is added to blk_1073741829_1005{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-01d6a639-f497-4e82-9260-5a273f48eddc:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-3d94ed3c-5f4b-43ca-bd30-94e88944fa04:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-7e1eec55-3690-41ef-a096-0965f3bfd294:NORMAL|RBW]]} size 0
2015-12-15 13:34:35,273 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: rod_test! blockNum = 6
2015-12-15 13:34:35,273 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: rod_test! t_DD != null
2015-12-15 13:34:35,273 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: rod_test! favoredDatanodeDescriptors != null
2015-12-15 13:34:35,273 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: rod_test! blockNum > 2
2015-12-15 13:34:35,273 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: rod_test! t_blocks.length = 5
2015-12-15 13:34:35,274 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /test3.mp4._COPYING_. BP-533550338-10.0.1.71-1450153894482 blk_1073741830_1006{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-7e1eec55-3690-41ef-a096-0965f3bfd294:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-bc2037c4-a713-429d-aac2-0ce6ad2e2605:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-523ac735-f848-47ac-bb54-5a6837e86db3:NORMAL|RBW]]}
2015-12-15 13:34:35,274 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 16 Total time for transactions(ms): 4 Number of transactions batched in Syncs: 0 Number of syncs: 6 SyncTimes(ms): 392 
2015-12-15 13:34:36,912 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.1.72:50010 is added to blk_1073741830_1006{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-7e1eec55-3690-41ef-a096-0965f3bfd294:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-bc2037c4-a713-429d-aac2-0ce6ad2e2605:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-523ac735-f848-47ac-bb54-5a6837e86db3:NORMAL|RBW]]} size 0
2015-12-15 13:34:36,914 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.1.73:50010 is added to blk_1073741830_1006{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-7e1eec55-3690-41ef-a096-0965f3bfd294:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-bc2037c4-a713-429d-aac2-0ce6ad2e2605:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-523ac735-f848-47ac-bb54-5a6837e86db3:NORMAL|RBW]]} size 0
2015-12-15 13:34:36,915 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 10.0.1.77:50010 is added to blk_1073741830_1006{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-7e1eec55-3690-41ef-a096-0965f3bfd294:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-bc2037c4-a713-429d-aac2-0ce6ad2e2605:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-523ac735-f848-47ac-bb54-5a6837e86db3:NORMAL|RBW]]} size 0
2015-12-15 13:34:36,977 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /test3.mp4._COPYING_ is closed by DFSClient_NONMAPREDUCE_1998260448_1
2015-12-15 13:34:48,756 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2015-12-15 13:34:48,758 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 2 millisecond(s).
2015-12-15 13:35:18,756 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2015-12-15 13:35:18,758 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2015-12-15 13:35:35,710 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: FSCK started by hduser (auth:SIMPLE) from /10.0.1.71 for path / at Tue Dec 15 13:35:35 KST 2015
2015-12-15 13:35:48,757 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2015-12-15 13:35:48,759 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2015-12-15 13:36:18,758 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2015-12-15 13:36:18,760 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2015-12-15 13:36:48,759 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2015-12-15 13:36:48,760 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 2 millisecond(s).
2015-12-15 13:37:18,759 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2015-12-15 13:37:18,760 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2015-12-15 13:37:48,759 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2015-12-15 13:37:48,761 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2015-12-15 13:38:18,760 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2015-12-15 13:38:18,761 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 2 millisecond(s).
2015-12-15 13:38:48,760 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2015-12-15 13:38:48,760 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2015-12-15 13:39:18,760 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2015-12-15 13:39:18,761 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 2 millisecond(s).
2015-12-15 13:39:48,759 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2015-12-15 13:39:48,761 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2015-12-15 13:39:57,430 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: list corrupt file blocks returned: 0
2015-12-15 13:40:06,017 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: list corrupt file blocks returned: 0
2015-12-15 13:40:14,663 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: list corrupt file blocks returned: 0
2015-12-15 13:40:18,760 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2015-12-15 13:40:18,761 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2015-12-15 13:40:48,761 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2015-12-15 13:40:48,762 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 2 millisecond(s).
2015-12-15 13:41:18,761 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2015-12-15 13:41:18,762 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2015-12-15 13:41:48,761 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2015-12-15 13:41:48,763 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2015-12-15 13:42:18,762 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2015-12-15 13:42:18,763 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 2 millisecond(s).
2015-12-15 13:42:48,762 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2015-12-15 13:42:48,762 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2015-12-15 13:43:18,761 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2015-12-15 13:43:18,763 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2015-12-15 13:43:48,762 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2015-12-15 13:43:48,764 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2015-12-15 13:44:18,763 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2015-12-15 13:44:18,764 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 2 millisecond(s).
2015-12-15 13:44:48,763 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2015-12-15 13:44:48,764 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
